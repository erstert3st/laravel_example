livedebugging {
	enabled = true
}

//--------------------syslogs-nodeexporter-----------

discovery.relabel "integrations_node_exporter" {
	targets = prometheus.exporter.unix.integrations_node_exporter.targets

	rule {
		// Set the instance label to the hostname of the machine
		target_label = "instance"
		replacement  = constants.hostname
	}

	rule {
		// Set a standard job name for all node_exporter metrics
		target_label = "job"
		replacement  = "node_exporter"
	}
}

prometheus.exporter.unix "integrations_node_exporter" {
	// Disable unnecessary collectors to reduce overhead
	disable_collectors = ["ipvs", "btrfs", "infiniband", "xfs", "zfs"]
	enable_collectors  = ["meminfo"]

	filesystem {
		// Exclude filesystem types that aren't relevant for monitoring
		fs_types_exclude = "^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|tmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$"
		// Exclude mount points that aren't relevant for monitoring
		mount_points_exclude = "^/(dev|proc|run/credentials/.+|sys|var/lib/docker/.+)($|/)"
		// Timeout for filesystem operations
		mount_timeout = "5s"
	}

	netclass {
		// Ignore virtual and container network interfaces
		ignored_devices = "^(veth.*|cali.*|[a-f0-9]{15})$"
	}

	netdev {
		// Exclude virtual and container network interfaces from device metrics
		device_exclude = "^(veth.*|cali.*|[a-f0-9]{15})$"
	}
}

// Define how to scrape metrics from the node_exporter
prometheus.scrape "integrations_node_exporter" {
	scrape_interval = "15s"
	// Use the targets with labels from the discovery.relabel component
	targets = discovery.relabel.integrations_node_exporter.output
	// Send the scraped metrics to the relabeling component
	forward_to = [prometheus.remote_write.mimir.receiver]
}

// Collect logs from systemd journal for node_exporter integration
loki.source.journal "logs_integrations_integrations_node_exporter_journal_scrape" {
	// Only collect logs from the last 24 hours
	max_age = "24h0m0s"
	// Apply relabeling rules to the logs
	relabel_rules = discovery.relabel.logs_integrations_integrations_node_exporter_journal_scrape.rules
	// Send logs to the local Loki instance
	forward_to = [loki.write.default.receiver]
}

// Define which log files to collect for node_exporter
local.file_match "logs_integrations_integrations_node_exporter_direct_scrape" {
	path_targets = [{
		// Target localhost for log collection
		__address__ = "localhost",
		// Collect standard system logs
		__path__ = "/var/log/{syslog,messages,*.log}",
		// Add instance label with hostname
		instance = constants.hostname,
		// Add job label for logs
		job = "node_exporter",
	}]
}

// Define relabeling rules for systemd journal logs
discovery.relabel "logs_integrations_integrations_node_exporter_journal_scrape" {
	targets = []

	rule {
		// Extract systemd unit information into a label
		source_labels = ["__journal__systemd_unit"]
		target_label  = "unit"
	}

	rule {
		// Extract boot ID information into a label
		source_labels = ["__journal__boot_id"]
		target_label  = "boot_id"
	}

	rule {
		// Extract transport information into a label
		source_labels = ["__journal__transport"]
		target_label  = "transport"
	}

	rule {
		// Extract log priority into a level label
		source_labels = ["__journal_priority_keyword"]
		target_label  = "level"
	}
}

// Collect logs from files for node_exporter
loki.source.file "logs_integrations_integrations_node_exporter_direct_scrape" {
	// Use targets defined in local.file_match
	targets = local.file_match.logs_integrations_integrations_node_exporter_direct_scrape.targets
	// Send logs to the local Loki instance
	forward_to = [loki.write.default.receiver]
}

//--------------------syslogs-nodeexporter-----------

//------------------apache----------------------  https://grafana.com/docs/grafana-cloud/monitor-infrastructure/integrations/integration-reference/integration-apache-http

prometheus.exporter.self "integrations_apache_http_histogram" { }

discovery.relabel "integrations_apache_http_histogram" {
	targets = prometheus.exporter.self.alloy.targets

	rule {
		replacement  = "apache_http"
		target_label = "job"
	}

	rule {
		source_labels = ["exported_instance"]
		target_label  = "instance" // may change that ^≈ù
	}
}

prometheus.scrape "integrations_apache_http_histogram" {
	targets    = discovery.relabel.integrations_apache_http_histogram.output
	forward_to = [prometheus.remote_write.mimir.receiver]
}

prometheus.exporter.apache "integrations_apache_http" {
	scrape_uri = "http://apache:80/server-status?auto"
}

discovery.relabel "integrations_apache_http" {
	targets = prometheus.exporter.apache.integrations_apache_http.targets

	rule {
		target_label = "instance"
		replacement  = constants.hostname
	}

	rule {
		target_label = "job"
		replacement  = "apache_http"
	}
}

prometheus.scrape "integrations_apache_http" {
	targets    = discovery.relabel.integrations_apache_http.output
	forward_to = [prometheus.remote_write.mimir.receiver]
	job_name   = "apache_http"
}

//--------------------------------------------apache access logs ------------------------------------------------------------------------------
loki.process "logs_integrations_integrations_apache_access" {
	forward_to = [loki.write.default.receiver]
	// forward_to = []

	stage.regex {
		expression = "^(?P<ip>[^ ]*) [^ ]* (?P<user>[^ ]*) \\[(?P<timestamp>[^\\]]*)\\] \"(?P<method>\\S+)(?: +(?P<path>[^ ]*) +\\S*)?\" (?P<code>[^ ]*) (?P<size>[^ ]*)(?: \"(?P<referer>[^\\\"]*)\" \"(?P<agent>.*)\")?$"
	}

	stage.metrics {
		metric.histogram {
			name        = "response_http_codes"
			description = "Apache responses by HTTP codes"
			source      = "code"
			prefix      = "apache_"
			buckets     = [199, 299, 399, 499, 599]
		}
	}

	stage.static_labels {
		values = {
			job            = "apache_access",
			service_name   = "apache",
			logtype        = "access",
			detected_level = "INFO",
		}
	}

	stage.labels {
		values = {
			method = null,
		}
	}
}

loki.source.file "logs_integrations_integrations_apache_access" {
	targets    = local.file_match.logs_integrations_integrations_apache_access.targets
	forward_to = [loki.process.logs_integrations_integrations_apache_access.receiver]
}
//------------------apache error logs---------------------------------------------------------------------
local.file_match "logs_integrations_integrations_apache_error" {
	path_targets = [{
		__address__ = "localhost",
		__path__    = "/mnt/log/apache2/error.log",
		instance    = constants.hostname,
		// instance    = "apache_web_server",
		job = "apache_http",
	}]
}

loki.process "logs_integrations_integrations_apache_error" {
	forward_to = [loki.write.default.receiver]
	// forward_to = []
	stage.regex {
		expression = "^\\[[^ ]* (?P<timestamp>[^\\]]*)\\] \\[(?:(?P<module>[^:\\]]+):)?(?P<level>[^\\]]+)\\](?: \\[pid (?P<pid>[^\\]]*)\\])?(?: \\[client (?P<client>[^\\]]*)\\])? (?P<message>.*)$"
	}

	stage.labels {
		values = {
			level  = null,
			module = null,
		}
	}

	stage.static_labels {
		values = {
			job          = "apache_error",
			service_name = "apache",
			logtype      = "error",
		}
	}
}

loki.source.file "logs_integrations_integrations_apache_error" {
	targets    = local.file_match.logs_integrations_integrations_apache_error.targets
	forward_to = [loki.process.logs_integrations_integrations_apache_error.receiver]
}

local.file_match "logs_integrations_integrations_apache_access" {
	path_targets = [{
		__address__ = "localhost",
		__path__    = "/mnt/log/apache2/access.log",
		instance    = constants.hostname,
		// instance    = "apache_web_server",
		job = "apache_http",
	}]
}
//------------------ Apache end -----------------------------------

//------------------ docker logs ----------------------------------------+

// ###############################
// #### Metrics Configuration ####
// ###############################

// Host Cadvisor on the Docker socket to expose container metrics.
prometheus.exporter.cadvisor "docker" {
	docker_only = true
}

discovery.relabel "docker" {
	targets = prometheus.exporter.cadvisor.docker.targets

	rule {
		target_label = "job"
		replacement  = "docker"
	}

	rule {
		target_label = "instance"
		replacement  = constants.hostname
	}

	rule {
		source_labels = ["__meta_docker_container_name"]
		regex         = "/(.*)"
		target_label  = "service_name"
	}
}

// Configure a prometheus.scrape component to collect cadvisor metrics.
prometheus.scrape "scraper" {
	targets    = discovery.relabel.docker.output
	forward_to = [prometheus.remote_write.mimir.receiver]

	scrape_interval = "10s"
}

// ###############################
// #### Logging Configuration ####
// ###############################

// Discover Docker containers and extract metadata.
discovery.docker "linux" {
	host = "unix:///var/run/docker.sock"
}

// Define a relabeling rule to create a service name from the container name.
discovery.relabel "logs_integrations_docker" {
	targets = []

	rule {
		source_labels = ["__meta_docker_container_name"]
		regex         = "/(.*)"
		target_label  = "container_name"
	}

	rule {
		target_label = "instance"
		replacement  = constants.hostname
	}
}

// Configure a loki.source.docker component to collect logs from Docker containers.
loki.source.docker "default" {
	host          = "unix:///var/run/docker.sock"
	targets       = discovery.docker.linux.targets
	labels        = {"platform" = "docker"}
	relabel_rules = discovery.relabel.logs_integrations_docker.rules
	forward_to    = [loki.write.default.receiver]
}

//------------------ Modsecurity logs -----------------------------------
loki.source.file "modsecurity_logs" {
	targets = [
		{__path__ = "/mnt/log/modsec/modsec_audit.log",
				job      = "modsecurity",
				app      = "modsecurity",
				env      = "env",
				instance = "modsecurity"}, //dont touch this line!
	]
	forward_to = [loki.process.modsecurity_logs.receiver]
}

loki.process "modsecurity_logs" {
	forward_to = [loki.write.default.receiver]

	stage.static_labels {
		values = {
			job          = "modsec",
			service_name = "modsec",
		}
	}

	stage.tenant {
		value = "sysmid-sensitive"
	}

	stage.json {
		expressions = {
			remote_address = "transaction.remote_address",
		}
	}

	stage.json {
		expressions = {
			request = "transaction",
		}
	}

	stage.json {
		expressions = {
			headers = "request",
		}
	}

	stage.json {
		expressions = {
			Host = "headers",
		}
	}

	stage.labels {
		values = {
			Host = null,
		}
	}

	stage.geoip {
		db      = "/geoip/GeoLite2-City.mmdb"
		source  = "remote_address"
		db_type = "city"
	}

	stage.labels {
		values = {
			remote_address           = null,
			geoip_city_name          = null,
			geoip_country_name       = "",
			geoip_country_code       = "",
			geoip_continent_name     = "",
			geoip_continent_code     = "",
			geoip_location_latitude  = "",
			geoip_location_longitude = "",
			geoip_postal_code        = "",
			geoip_timezone           = "",
			geoip_subdivision_name   = "",
			geoip_subdivision_code   = "",
		}
	}

	stage.label_drop {
		values = ["geoip_subdivision_name",
			"response_headers_Content_Length",
			"filename",
			"audit_data_stopwatch_gc",
			"audit_data_stopwatch_l",
			"audit_data_stopwatch_p1",
			"audit_data_stopwatch_p2",
			"audit_data_stopwatch_p3",
			"audit_data_stopwatch_p4",
			"audit_data_stopwatch_p5",
			"audit_data_stopwatch_sr",
			"audit_data_stopwatch_sw",
			"audit_data_action_phase",
			"audit_data_engine_mode",
			"audit_data_response_body_dechunked",
			// "remote_address"
		]
	}
}

//------------------ Modsecurity logs end -----------------------------
//
//------------------ Fail2Ban logs -----------------------------------

loki.source.file "fail2ban" {
	targets = [
		{__path__ = "/mnt/log/fail2ban/fail2ban.log",
				job = "fail2ban"},
	]
	forward_to = [loki.process.fail2ban.receiver]
}

loki.process "fail2ban" {
	forward_to = [loki.write.default.receiver]

	stage.multiline {
		firstline     = "\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}(?:,\\d{3})?"
		max_wait_time = "10s"
	}

	stage.regex {
		expression = "^(?s)(?P<time>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}(?:,\\d{3})?)\\s+fail2ban\\.(?P<component>\\S+)\\s+\\[(?P<pid>\\d+)\\]:\\s+(?P<detected_level>\\S+)\\s+(?:\\[(?P<rule>[^\\]]+)\\]\\s+)?(?P<message>.*)$"
	}

	stage.timestamp {
		source = "time"
		format = "2006-01-02 15:04:05,000"
	}

	stage.labels {
		values = {
			component      = null,
			detected_level = null,
			rule           = null,
		}
	}

	stage.output {
		source = "message"
	}

	stage.match {
		selector = "{job=\"fail2ban\"} |~ \"\\\\\\\\[\\\\\\\\S+\\\\\\\\] .*\""

		stage.regex {
			expression = "(\\[(?P<jail>\\S+)\\] )?(?P<message>.*?)$"
		}

		stage.labels {
			values = {
				jail = null,
			}
		}

		stage.output {
			source = "message"
		}
	}

	stage.regex {
		expression = ".*?(?P<remote_addr>\\d+\\.\\d+\\.\\d+\\.\\d+).*"
	}

	stage.geoip {
		db      = "/geoip/GeoLite2-City.mmdb"
		source  = "remote_addr"
		db_type = "city"
	}

	stage.labels {
		values = {
			geoip_city_name          = null,
			geoip_country_name       = null,
			geoip_country_code       = null,
			geoip_continent_name     = null,
			geoip_continent_code     = null,
			geoip_location_latitude  = null,
			geoip_location_longitude = null,
			geoip_postal_code        = null,
			geoip_timezone           = null,
			geoip_subdivision_name   = null,
			geoip_subdivision_code   = null,
		}
	}

	stage.label_drop {
		values = ["filename"]
	}

	stage.static_labels {
		values = {
			job          = "fail2ban",
			service_name = "fail2ban",
		}
	}
}

// ----------------- internal logs -----------------------------------
logging {
	// level    = "debug"
	level    = "info"
	write_to = [loki.process.example.receiver]
}

loki.process "example" {
	forward_to = [loki.relabel.alloy_logs.receiver]

	stage.labels {
		values = {
			version = string.format("Hello%s", "1.0.0"),
		}
	}
}
// ----------------- internal logs end -----------------------------------

// ----------------- scraper -----------------------------------
// Collect metrics from the local running Alloy instance and forward to
// Prometheus.

// Collect profiles from the local running Alloy instance and forward to
// Pyroscope.
pyroscope.scrape "alloy" {
	targets = [
		{"__address__" = "localhost:12345", "service_name" = "alloy"},
	]
	forward_to = [pyroscope.write.pyroscope.receiver]
}

prometheus.scrape "grafana" {
	targets = [
		{"__address__" = "grafana:3000", "job" = "grafana"},
	]
	forward_to = [prometheus.remote_write.mimir.receiver]
}

prometheus.scrape "mimir" {
	targets = [
		{"__address__" = "mimir:9009", "job" = "loki"},
	]
	forward_to = [prometheus.remote_write.mimir.receiver]
}

prometheus.scrape "tempo" {
	targets = [
		{"__address__" = "tempo:3200", "job" = "loki"},
	]
	forward_to = [prometheus.remote_write.mimir.receiver]
}

prometheus.scrape "loki" {
	targets = [
		{"__address__" = "loki:3100", "job" = "loki"},
	]
	forward_to = [prometheus.remote_write.mimir.receiver]
}

prometheus.scrape "pyroscope" {
	targets = [
		{"__address__" = "pyroscope:4040", "job" = "pyroscope"},
	]
	forward_to = [prometheus.remote_write.mimir.receiver]
}

prometheus.scrape "docker_state_exporter" {
	targets = [
		{"__address__" = "docker_state_exporter:8080", "job" = "docker_state"},
	]
	forward_to = [prometheus.remote_write.mimir.receiver]
}

prometheus.scrape "mysqldexporter" {
	targets = [
		{"__address__" = "mysqldexporter:9104", "job" = "mysqlex"},
	]
	forward_to = [prometheus.remote_write.mimir.receiver]
}

prometheus.scrape "apacheexporter" {
	targets = [
		{"__address__" = "apacheexporter:9117", "job" = "apacheex"},
	]
	forward_to = [prometheus.remote_write.mimir.receiver]
}

prometheus.scrape "phpfpmexporter" {
	targets = [
		{__address__ = "phpfpmexporter:9253",
				__metrics_path__ = "/metrics",
				"job"            = "phpfpmex",
		},
	]

	forward_to      = [prometheus.remote_write.mimir.receiver]
	scrape_interval = "15s"
}

// ----------------- scraper end -----------------------------------

// ----------------- OpenTelemetry logs start -----------------------------------

otelcol.receiver.otlp "default" {
	grpc { }

	http { }

	output {
		logs   = [otelcol.processor.batch.default.input]
		traces = [otelcol.processor.batch.default.input]
	}
}

otelcol.processor.batch "default" {
	output {
		logs   = [otelcol.exporter.debug.default.input]
		traces = [otelcol.exporter.debug.default.input]
	}
}

otelcol.exporter.debug "default" {
	verbosity = "Detailed"
}

otelcol.exporter.otlp "tempo" {
	client {
		endpoint = coalesce(sys.env("TEMPO_HOST"), "localhost:4317")

		tls {
			insecure = true
		}
	}
}
// ----------------- OpenTelemetry logs end -----------------------------------

prometheus.exporter.self "alloy" { }

prometheus.scrape "alloy" {
	targets    = prometheus.exporter.self.alloy.targets
	forward_to = [prometheus.remote_write.mimir.receiver]
}

// ----------------- Alloy logs -----------------------------------
loki.relabel "alloy_logs" {
	rule {
		target_label = "instance"
		replacement  = string.format("version%s", "1.0.0")
	}

	rule {
		target_label = "job"
		replacement  = "alloy"
	}

	forward_to = [loki.write.default.receiver]
}

tracing {
	// Write all spans. Don't do this in production! prod zb 0.1
	sampling_fraction = 1.0

	// Forward internal spans to the local Tempo instance.
	write_to = [otelcol.exporter.otlp.tempo.input]
}

// ----------------- Writer  start -----------------------------------

prometheus.remote_write "mimir" {
	endpoint {
		url = string.format(
			"http://%s/api/v1/push",
			coalesce(sys.env("REMOTE_WRITE_HOST"), "localhost:9009"),
		)
	}
}

loki.write "default" {
	endpoint {
		url = string.format(
			"http://%s/loki/api/v1/push",
			coalesce(sys.env("LOKI_HOST"), "localhost:3100"),
		)
	}
}

pyroscope.write "pyroscope" {
	endpoint {
		url = string.format(
			"http://%s",
			coalesce(sys.env("PYROSCOPE_HOST"), "localhost:4040"),
		)
	}
}

// ----------------- Writer end -----------------------------------

//loki.process "laravel_logs" {
//  forward_to = [loki.relabel.laravel_logs.receiver]

//stage.labels {
//   values = {
//      service_name = "laravel"
//  }
// }
//}

//loki.relabel "laravel_logs" {
//rule {
//target_label = "service_name"
// replacement  = "laravel"
// }

//  rule {
//    target_label = "instance"
//    replacement  = "laravel"
//  }

//  rule {
//    target_label = "job"
//    replacement  = "app/laravel"
//  }
//
//  forward_to = [loki.write.default.receiver]
//}
